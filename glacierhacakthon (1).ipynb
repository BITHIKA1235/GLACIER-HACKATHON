{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1143211-73b1-4064-832a-6bf7aedbfb7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'GLACIER HACKATHON\\\\train\\\\Train\\\\Band1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m band_files_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m band_dir \u001b[38;5;129;01min\u001b[39;00m band_dirs:\n\u001b[1;32m---> 35\u001b[0m     files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(band_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.img\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m     36\u001b[0m     files\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m     37\u001b[0m     band_files_list\u001b[38;5;241m.\u001b[39mappend(files)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'GLACIER HACKATHON\\\\train\\\\Train\\\\Band1'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import rasterio\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import re\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load dataset with proper validation split\n",
    "# -------------------------\n",
    "base_dir = os.path.join(\"GLACIER HACKATHON\", \"train\", \"Train\")\n",
    "band_dirs = [\n",
    "    os.path.join(base_dir, \"Band1\"),\n",
    "    os.path.join(base_dir, \"Band2\"),\n",
    "    os.path.join(base_dir, \"Band3\"),\n",
    "    os.path.join(base_dir, \"Band4\"),\n",
    "    os.path.join(base_dir, \"Band5\")\n",
    "]\n",
    "label_dir = os.path.join(base_dir, \"label\")\n",
    "\n",
    "# Collect band and label files\n",
    "band_files_list = []\n",
    "for band_dir in band_dirs:\n",
    "    files = [f for f in os.listdir(band_dir) if f.lower().endswith(('.tif', '.img'))]\n",
    "    files.sort()\n",
    "    band_files_list.append(files)\n",
    "\n",
    "label_files = [f for f in os.listdir(label_dir) if f.lower().endswith(('.tif', '.img'))]\n",
    "label_files.sort()\n",
    "\n",
    "# -------------------------\n",
    "# 2. Key Improvement: Split by glacier region (geographical split)\n",
    "# -------------------------\n",
    "def extract_region_id(filename):\n",
    "    \"\"\"Extract region identifier from filename\"\"\"\n",
    "    patterns = [\n",
    "        r'(Region[A-Z]+)_glacier',\n",
    "        r'([A-Za-z]+)_glacier',\n",
    "        r'(region[A-Z]+)_',\n",
    "        r'([A-Za-z0-9]+)_glacier'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, filename, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return filename.split('_')[0]\n",
    "\n",
    "region_files = {}\n",
    "for label_file in label_files:\n",
    "    region_id = extract_region_id(label_file)\n",
    "    if region_id not in region_files:\n",
    "        region_files[region_id] = []\n",
    "    region_files[region_id].append(label_file)\n",
    "\n",
    "regions = list(region_files.keys())\n",
    "print(f\"Available regions: {regions}\")\n",
    "\n",
    "if len(regions) < 2:\n",
    "    random.shuffle(label_files)\n",
    "    split_idx = int(0.8 * len(label_files))\n",
    "    train_label_files = label_files[:split_idx]\n",
    "    val_label_files = label_files[split_idx:]\n",
    "    print(\"Warning: Only one region found, using random split\")\n",
    "else:\n",
    "    val_region = regions[0]\n",
    "    train_regions = regions[1:]\n",
    "    train_label_files = []\n",
    "    for region in train_regions:\n",
    "        train_label_files.extend(region_files[region])\n",
    "    val_label_files = region_files[val_region]\n",
    "\n",
    "print(f\"Training samples: {len(train_label_files)}\")\n",
    "print(f\"Validation samples: {len(val_label_files)}\")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Data Augmentation Transformations\n",
    "# -------------------------\n",
    "class SatelliteTransform:\n",
    "    def __init__(self, augment=False):\n",
    "        self.augment = augment\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        if self.augment:\n",
    "            if random.random() > 0.5:\n",
    "                image = torch.flip(image, [2])\n",
    "                mask = torch.flip(mask, [1])\n",
    "            if random.random() > 0.5:\n",
    "                image = torch.flip(image, [1])\n",
    "                mask = torch.flip(mask, [0])\n",
    "            rot = random.choice([0, 1, 2, 3])\n",
    "            image = torch.rot90(image, rot, [1, 2])\n",
    "            mask = torch.rot90(mask, rot, [0, 1])\n",
    "        return image, mask\n",
    "\n",
    "# -------------------------\n",
    "# 4. Dataset class with improved file matching\n",
    "# -------------------------\n",
    "def extract_common_id(filename):\n",
    "    patterns = [\n",
    "        r'(Region[A-Z]+_glacier\\d+)',\n",
    "        r'([A-Za-z]+_glacier\\d+)',\n",
    "        r'([A-Za-z0-9]+_glacier\\d+)',\n",
    "        r'(glacier\\d+_[A-Za-z0-9]+)',\n",
    "        r'([A-Za-z0-9]+_\\d+)'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, filename, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    filename = filename.replace('B2_', '').replace('B3_', '').replace('B4_', '').replace('B6_', '').replace('B10_', '')\n",
    "    filename = filename.replace('Y_output_resized_', '').replace('mask_', '').replace('label_', '')\n",
    "    return os.path.splitext(filename)[0]\n",
    "\n",
    "class GlacierDataset(Dataset):\n",
    "    def __init__(self, band_dirs, band_files_list, label_dir, label_files, transform=None):\n",
    "        self.band_dirs = band_dirs\n",
    "        self.band_files_list = band_files_list\n",
    "        self.label_dir = label_dir\n",
    "        self.label_files = label_files\n",
    "        self.transform = transform\n",
    "        self.file_mapping = self._create_file_mapping()\n",
    "\n",
    "    def _create_file_mapping(self):\n",
    "        mapping = {}\n",
    "        for label_file in self.label_files:\n",
    "            common_id = extract_common_id(label_file)\n",
    "            band_files = []\n",
    "            for band_files_in_dir in self.band_files_list:\n",
    "                found_file = None\n",
    "                for band_file in band_files_in_dir:\n",
    "                    band_common_id = extract_common_id(band_file)\n",
    "                    if band_common_id == common_id:\n",
    "                        found_file = band_file\n",
    "                        break\n",
    "                if found_file is None:\n",
    "                    label_base = os.path.splitext(label_file)[0]\n",
    "                    for band_file in band_files_in_dir:\n",
    "                        band_base = os.path.splitext(band_file)[0]\n",
    "                        if label_base in band_base or band_base in label_base:\n",
    "                            found_file = band_file\n",
    "                            break\n",
    "                band_files.append(found_file)\n",
    "            mapping[label_file] = band_files\n",
    "        return mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label_file = self.label_files[idx]\n",
    "        label_path = os.path.join(self.label_dir, label_file)\n",
    "        with rasterio.open(label_path) as src:\n",
    "            label_data = src.read(1)\n",
    "        label_tensor = torch.tensor(label_data, dtype=torch.float32)\n",
    "        band_files = self.file_mapping[label_file]\n",
    "        band_stack = []\n",
    "        for band_idx, band_file in enumerate(band_files):\n",
    "            if band_file is None:\n",
    "                band_data = np.zeros_like(label_data)\n",
    "            else:\n",
    "                band_path = os.path.join(self.band_dirs[band_idx], band_file)\n",
    "                with rasterio.open(band_path) as src:\n",
    "                    band_data = src.read(1)\n",
    "            band_stack.append(band_data)\n",
    "        image_tensor = torch.tensor(np.stack(band_stack, axis=0), dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            image_tensor, label_tensor = self.transform(image_tensor, label_tensor)\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "train_transform = SatelliteTransform(augment=True)\n",
    "val_transform = SatelliteTransform(augment=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_dataset = GlacierDataset(band_dirs, band_files_list, label_dir, train_label_files, transform=train_transform)\n",
    "    val_dataset = GlacierDataset(band_dirs, band_files_list, label_dir, val_label_files, transform=val_transform)\n",
    "\n",
    "    # Use num_workers=0 for Windows or wrap in __main__ as shown\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # -------------------------\n",
    "    # 5. MCC Calculation Function\n",
    "    # -------------------------\n",
    "    def calculate_mcc(predictions, targets):\n",
    "        pred_binary = (torch.sigmoid(predictions) > 0.5).float()\n",
    "        targets = targets.unsqueeze(1) if targets.ndim == 3 else targets\n",
    "        pred_flat = pred_binary.view(-1).cpu().numpy()\n",
    "        target_flat = targets.view(-1).cpu().numpy()\n",
    "        if np.all(pred_flat == pred_flat[0]) or np.all(target_flat == target_flat[0]):\n",
    "            return 0.0\n",
    "        return matthews_corrcoef(target_flat, pred_flat)\n",
    "\n",
    "    # -------------------------\n",
    "    # 6. Define UNet model with improvements\n",
    "    # -------------------------\n",
    "    class DoubleConv(nn.Module):\n",
    "        def __init__(self, in_ch, out_ch):\n",
    "            super().__init__()\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.conv(x)\n",
    "\n",
    "    class UNet(nn.Module):\n",
    "        def __init__(self, in_ch=5, out_ch=1):\n",
    "            super().__init__()\n",
    "            self.enc1 = DoubleConv(in_ch, 64)\n",
    "            self.enc2 = DoubleConv(64, 128)\n",
    "            self.enc3 = DoubleConv(128, 256)\n",
    "            self.enc4 = DoubleConv(256, 512)\n",
    "            self.pool = nn.MaxPool2d(2)\n",
    "            self.bottleneck = DoubleConv(512, 1024)\n",
    "            self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "            self.dec4 = DoubleConv(1024, 512)\n",
    "            self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "            self.dec3 = DoubleConv(512, 256)\n",
    "            self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "            self.dec2 = DoubleConv(256, 128)\n",
    "            self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "            self.dec1 = DoubleConv(128, 64)\n",
    "            self.final = nn.Conv2d(64, out_ch, 1)\n",
    "        def forward(self, x):\n",
    "            e1 = self.enc1(x)\n",
    "            e2 = self.enc2(self.pool(e1))\n",
    "            e3 = self.enc3(self.pool(e2))\n",
    "            e4 = self.enc4(self.pool(e3))\n",
    "            b = self.bottleneck(self.pool(e4))\n",
    "            d4 = self.up4(b)\n",
    "            d4 = torch.cat([d4, e4], dim=1)\n",
    "            d4 = self.dec4(d4)\n",
    "            d3 = self.up3(d4)\n",
    "            d3 = torch.cat([d3, e3], dim=1)\n",
    "            d3 = self.dec3(d3)\n",
    "            d2 = self.up2(d3)\n",
    "            d2 = torch.cat([d2, e2], dim=1)\n",
    "            d2 = self.dec2(d2)\n",
    "            d1 = self.up1(d2)\n",
    "            d1 = torch.cat([d1, e1], dim=1)\n",
    "            d1 = self.dec1(d1)\n",
    "            return self.final(d1)\n",
    "\n",
    "    # -------------------------\n",
    "    # 7. Setup device & model\n",
    "    # -------------------------\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = UNet(in_ch=5, out_ch=1).to(device)\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 8. Training loop with validation and MCC-based model selection\n",
    "    # -------------------------\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5)\n",
    "\n",
    "    num_epochs = 20\n",
    "    best_mcc = -1.0\n",
    "    best_model = None\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_mccs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_batches = 0\n",
    "        for images, masks in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Train\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            # Resize masks if needed\n",
    "            if masks.ndim == 3:\n",
    "                masks = masks.unsqueeze(1)\n",
    "            if masks.shape[2:] != outputs.shape[2:]:\n",
    "                masks = F.interpolate(masks.float(), size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "            loss = criterion(outputs, masks.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_batches += 1\n",
    "        train_loss /= train_batches\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_batches = 0\n",
    "        val_mcc_scores = []\n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} - Val\"):\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "                # Resize masks if needed\n",
    "                if masks.ndim == 3:\n",
    "                    masks = masks.unsqueeze(1)\n",
    "                if masks.shape[2:] != outputs.shape[2:]:\n",
    "                    masks = F.interpolate(masks.float(), size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "                loss = criterion(outputs, masks.float())\n",
    "                val_loss += loss.item()\n",
    "                val_batches += 1\n",
    "                mcc = calculate_mcc(outputs, masks)\n",
    "                val_mcc_scores.append(mcc)\n",
    "        val_loss /= val_batches\n",
    "        avg_val_mcc = np.mean(val_mcc_scores)\n",
    "        val_losses.append(val_loss)\n",
    "        val_mccs.append(avg_val_mcc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: \"\n",
    "              f\"Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Val MCC: {avg_val_mcc:.4f}, \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        if avg_val_mcc > best_mcc:\n",
    "            best_mcc = avg_val_mcc\n",
    "            best_model = model.state_dict().copy()\n",
    "            torch.save(best_model, \"model.pth\")\n",
    "            print(f\"✅ Best model updated with MCC: {best_mcc:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_val_mcc)\n",
    "\n",
    "        if epoch > 10 and avg_val_mcc < max(val_mccs[-5:]):\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # Load best model for final evaluation\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    final_mcc_scores = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            # Resize masks if needed\n",
    "            if masks.ndim == 3:\n",
    "                masks = masks.unsqueeze(1)\n",
    "            if masks.shape[2:] != outputs.shape[2:]:\n",
    "                masks = F.interpolate(masks.float(), size=outputs.shape[2:], mode='bilinear', align_corners=False)\n",
    "            mcc = calculate_mcc(outputs, masks)\n",
    "            final_mcc_scores.append(mcc)\n",
    "\n",
    "    final_mcc = np.mean(final_mcc_scores)\n",
    "    print(f\"Final MCC on unseen region: {final_mcc:.4f}\")\n",
    "    print(f\"Best model saved as 'model.pth' with MCC: {best_mcc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517d8f48-1af3-4134-aa0b-b79997b5a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Files extracted to: newfolder\n",
      "📂 Folder: newfolder\n",
      "📂 Folder: newfolder\\Train\n",
      "📂 Folder: newfolder\\Train\\Band1\n",
      "   - B2_B2_masked_02_07.tif\n",
      "   - B2_B2_masked_02_08.tif\n",
      "   - B2_B2_masked_03_07.tif\n",
      "   - B2_B2_masked_03_09.tif\n",
      "   - B2_B2_masked_03_11.tif\n",
      "   - B2_B2_masked_04_08.tif\n",
      "   - B2_B2_masked_04_09.tif\n",
      "   - B2_B2_masked_04_10.tif\n",
      "   - B2_B2_masked_05_08.tif\n",
      "   - B2_B2_masked_05_09.tif\n",
      "   - B2_B2_masked_05_10.tif\n",
      "   - B2_B2_masked_06_09.tif\n",
      "   - B2_B2_masked_06_11.tif\n",
      "   - B2_B2_masked_06_12.tif\n",
      "   - B2_B2_masked_07_10.tif\n",
      "   - B2_B2_masked_07_11.tif\n",
      "   - B2_B2_masked_07_13.tif\n",
      "   - B2_B2_masked_08_12.tif\n",
      "   - B2_B2_masked_08_13.tif\n",
      "   - B2_B2_masked_08_14.tif\n",
      "   - B2_B2_masked_09_13.tif\n",
      "   - B2_B2_masked_09_14.tif\n",
      "   - B2_B2_masked_10_12.tif\n",
      "   - B2_B2_masked_11_13.tif\n",
      "   - B2_B2_masked_12_12.tif\n",
      "📂 Folder: newfolder\\Train\\Band2\n",
      "   - B3_B3_masked_02_07.tif\n",
      "   - B3_B3_masked_02_08.tif\n",
      "   - B3_B3_masked_03_07.tif\n",
      "   - B3_B3_masked_03_09.tif\n",
      "   - B3_B3_masked_03_11.tif\n",
      "   - B3_B3_masked_04_08.tif\n",
      "   - B3_B3_masked_04_09.tif\n",
      "   - B3_B3_masked_04_10.tif\n",
      "   - B3_B3_masked_05_08.tif\n",
      "   - B3_B3_masked_05_09.tif\n",
      "   - B3_B3_masked_05_10.tif\n",
      "   - B3_B3_masked_06_09.tif\n",
      "   - B3_B3_masked_06_11.tif\n",
      "   - B3_B3_masked_06_12.tif\n",
      "   - B3_B3_masked_07_10.tif\n",
      "   - B3_B3_masked_07_11.tif\n",
      "   - B3_B3_masked_07_13.tif\n",
      "   - B3_B3_masked_08_12.tif\n",
      "   - B3_B3_masked_08_13.tif\n",
      "   - B3_B3_masked_08_14.tif\n",
      "   - B3_B3_masked_09_13.tif\n",
      "   - B3_B3_masked_09_14.tif\n",
      "   - B3_B3_masked_10_12.tif\n",
      "   - B3_B3_masked_11_13.tif\n",
      "   - B3_B3_masked_12_12.tif\n",
      "📂 Folder: newfolder\\Train\\Band3\n",
      "   - B4_B4_masked_02_07.tif\n",
      "   - B4_B4_masked_02_08.tif\n",
      "   - B4_B4_masked_03_07.tif\n",
      "   - B4_B4_masked_03_09.tif\n",
      "   - B4_B4_masked_03_11.tif\n",
      "   - B4_B4_masked_04_08.tif\n",
      "   - B4_B4_masked_04_09.tif\n",
      "   - B4_B4_masked_04_10.tif\n",
      "   - B4_B4_masked_05_08.tif\n",
      "   - B4_B4_masked_05_09.tif\n",
      "   - B4_B4_masked_05_10.tif\n",
      "   - B4_B4_masked_06_09.tif\n",
      "   - B4_B4_masked_06_11.tif\n",
      "   - B4_B4_masked_06_12.tif\n",
      "   - B4_B4_masked_07_10.tif\n",
      "   - B4_B4_masked_07_11.tif\n",
      "   - B4_B4_masked_07_13.tif\n",
      "   - B4_B4_masked_08_12.tif\n",
      "   - B4_B4_masked_08_13.tif\n",
      "   - B4_B4_masked_08_14.tif\n",
      "   - B4_B4_masked_09_13.tif\n",
      "   - B4_B4_masked_09_14.tif\n",
      "   - B4_B4_masked_10_12.tif\n",
      "   - B4_B4_masked_11_13.tif\n",
      "   - B4_B4_masked_12_12.tif\n",
      "📂 Folder: newfolder\\Train\\Band4\n",
      "   - B6_B6_masked_02_07.tif\n",
      "   - B6_B6_masked_02_08.tif\n",
      "   - B6_B6_masked_03_07.tif\n",
      "   - B6_B6_masked_03_09.tif\n",
      "   - B6_B6_masked_03_11.tif\n",
      "   - B6_B6_masked_04_08.tif\n",
      "   - B6_B6_masked_04_09.tif\n",
      "   - B6_B6_masked_04_10.tif\n",
      "   - B6_B6_masked_05_08.tif\n",
      "   - B6_B6_masked_05_09.tif\n",
      "   - B6_B6_masked_05_10.tif\n",
      "   - B6_B6_masked_06_09.tif\n",
      "   - B6_B6_masked_06_11.tif\n",
      "   - B6_B6_masked_06_12.tif\n",
      "   - B6_B6_masked_07_10.tif\n",
      "   - B6_B6_masked_07_11.tif\n",
      "   - B6_B6_masked_07_13.tif\n",
      "   - B6_B6_masked_08_12.tif\n",
      "   - B6_B6_masked_08_13.tif\n",
      "   - B6_B6_masked_08_14.tif\n",
      "   - B6_B6_masked_09_13.tif\n",
      "   - B6_B6_masked_09_14.tif\n",
      "   - B6_B6_masked_10_12.tif\n",
      "   - B6_B6_masked_11_13.tif\n",
      "   - B6_B6_masked_12_12.tif\n",
      "📂 Folder: newfolder\\Train\\Band5\n",
      "   - B10_B10_masked_02_07.tif\n",
      "   - B10_B10_masked_02_08.tif\n",
      "   - B10_B10_masked_03_07.tif\n",
      "   - B10_B10_masked_03_09.tif\n",
      "   - B10_B10_masked_03_11.tif\n",
      "   - B10_B10_masked_04_08.tif\n",
      "   - B10_B10_masked_04_09.tif\n",
      "   - B10_B10_masked_04_10.tif\n",
      "   - B10_B10_masked_05_08.tif\n",
      "   - B10_B10_masked_05_09.tif\n",
      "   - B10_B10_masked_05_10.tif\n",
      "   - B10_B10_masked_06_09.tif\n",
      "   - B10_B10_masked_06_11.tif\n",
      "   - B10_B10_masked_06_12.tif\n",
      "   - B10_B10_masked_07_10.tif\n",
      "   - B10_B10_masked_07_11.tif\n",
      "   - B10_B10_masked_07_13.tif\n",
      "   - B10_B10_masked_08_12.tif\n",
      "   - B10_B10_masked_08_13.tif\n",
      "   - B10_B10_masked_08_14.tif\n",
      "   - B10_B10_masked_09_13.tif\n",
      "   - B10_B10_masked_09_14.tif\n",
      "   - B10_B10_masked_10_12.tif\n",
      "   - B10_B10_masked_11_13.tif\n",
      "   - B10_B10_masked_12_12.tif\n",
      "📂 Folder: newfolder\\Train\\label\n",
      "   - Y_output_resized_02_07.tif\n",
      "   - Y_output_resized_02_08.tif\n",
      "   - Y_output_resized_03_07.tif\n",
      "   - Y_output_resized_03_09.tif\n",
      "   - Y_output_resized_03_11.tif\n",
      "   - Y_output_resized_04_08.tif\n",
      "   - Y_output_resized_04_09.tif\n",
      "   - Y_output_resized_04_10.tif\n",
      "   - Y_output_resized_05_08.tif\n",
      "   - Y_output_resized_05_09.tif\n",
      "   - Y_output_resized_05_10.tif\n",
      "   - Y_output_resized_06_09.tif\n",
      "   - Y_output_resized_06_11.tif\n",
      "   - Y_output_resized_06_12.tif\n",
      "   - Y_output_resized_07_10.tif\n",
      "   - Y_output_resized_07_11.tif\n",
      "   - Y_output_resized_07_13.tif\n",
      "   - Y_output_resized_08_12.tif\n",
      "   - Y_output_resized_08_13.tif\n",
      "   - Y_output_resized_08_14.tif\n",
      "   - Y_output_resized_09_13.tif\n",
      "   - Y_output_resized_09_14.tif\n",
      "   - Y_output_resized_10_12.tif\n",
      "   - Y_output_resized_11_13.tif\n",
      "   - Y_output_resized_12_12.tif\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"train.zip\"   \n",
    "extract_path = \"newfolder\"\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"✅ Files extracted to:\", extract_path)\n",
    "\n",
    "        # Walk through extracted folder\n",
    "        for root, dirs, files in os.walk(extract_path):\n",
    "            print(\"📂 Folder:\", root)\n",
    "            for f in files:\n",
    "                print(\"   -\", f)\n",
    "\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"❌ Error: The file is not a valid zip or is corrupted.\")\n",
    "else:\n",
    "    print(\"❌ Error: File not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861a72c5-4024-4c3a-8c0f-631fd87c0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import rasterio\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import re\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1148f270-3fe2-419b-bc90-af918234d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b22aee-381d-4066-a477-5c2be8f867d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data\n",
      "  DIR: Train\n",
      "----------------------------------------\n",
      "train_data\\Train\n",
      "  DIR: Band1\n",
      "  DIR: Band2\n",
      "  DIR: Band3\n",
      "  DIR: Band4\n",
      "  DIR: Band5\n",
      "  DIR: label\n",
      "----------------------------------------\n",
      "train_data\\Train\\Band1\n",
      "  FILE: B2_B2_masked_02_07.tif\n",
      "  FILE: B2_B2_masked_02_08.tif\n",
      "  FILE: B2_B2_masked_03_07.tif\n",
      "  FILE: B2_B2_masked_03_09.tif\n",
      "  FILE: B2_B2_masked_03_11.tif\n",
      "----------------------------------------\n",
      "train_data\\Train\\Band2\n",
      "  FILE: B3_B3_masked_02_07.tif\n",
      "  FILE: B3_B3_masked_02_08.tif\n",
      "  FILE: B3_B3_masked_03_07.tif\n",
      "  FILE: B3_B3_masked_03_09.tif\n",
      "  FILE: B3_B3_masked_03_11.tif\n",
      "----------------------------------------\n",
      "train_data\\Train\\Band3\n",
      "  FILE: B4_B4_masked_02_07.tif\n",
      "  FILE: B4_B4_masked_02_08.tif\n",
      "  FILE: B4_B4_masked_03_07.tif\n",
      "  FILE: B4_B4_masked_03_09.tif\n",
      "  FILE: B4_B4_masked_03_11.tif\n",
      "----------------------------------------\n",
      "train_data\\Train\\Band4\n",
      "  FILE: B6_B6_masked_02_07.tif\n",
      "  FILE: B6_B6_masked_02_08.tif\n",
      "  FILE: B6_B6_masked_03_07.tif\n",
      "  FILE: B6_B6_masked_03_09.tif\n",
      "  FILE: B6_B6_masked_03_11.tif\n",
      "----------------------------------------\n",
      "train_data\\Train\\Band5\n",
      "  FILE: B10_B10_masked_02_07.tif\n",
      "  FILE: B10_B10_masked_02_08.tif\n",
      "  FILE: B10_B10_masked_03_07.tif\n",
      "  FILE: B10_B10_masked_03_09.tif\n",
      "  FILE: B10_B10_masked_03_11.tif\n",
      "----------------------------------------\n",
      "train_data\\Train\\label\n",
      "  FILE: Y_output_resized_02_07.tif\n",
      "  FILE: Y_output_resized_02_08.tif\n",
      "  FILE: Y_output_resized_03_07.tif\n",
      "  FILE: Y_output_resized_03_09.tif\n",
      "  FILE: Y_output_resized_03_11.tif\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"train_data\"):\n",
    "    print(root)\n",
    "    for d in dirs:\n",
    "        print(\"  DIR:\", d)\n",
    "    for f in files[:5]:  # only print first 5 files\n",
    "        print(\"  FILE:\", f)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d41659b2-6174-4706-9ae0-a6f790dbee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ train_data already exists, skipping extraction\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'train_data\\\\Band1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m band_files_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m band_dir \u001b[38;5;129;01min\u001b[39;00m band_dirs:\n\u001b[1;32m---> 42\u001b[0m     files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(band_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.img\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m     43\u001b[0m     files\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m     44\u001b[0m     band_files_list\u001b[38;5;241m.\u001b[39mappend(files)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'train_data\\\\Band1'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# =========================================================\n",
    "# 1. Extract train.zip\n",
    "# =========================================================\n",
    "base_dir = \"train_data\"\n",
    "zip_path = \"train.zip\"\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(base_dir)\n",
    "    print(f\"✅ Extracted {zip_path} to {base_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ {base_dir} already exists, skipping extraction\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. Define band and label directories\n",
    "# =========================================================\n",
    "band_dirs = [\n",
    "    os.path.join(base_dir, \"Band1\"),\n",
    "    os.path.join(base_dir, \"Band2\"),\n",
    "    os.path.join(base_dir, \"Band3\"),\n",
    "    os.path.join(base_dir, \"Band4\"),\n",
    "    os.path.join(base_dir, \"Band5\")\n",
    "]\n",
    "label_dir = os.path.join(base_dir, \"label\")\n",
    "\n",
    "band_files_list = []\n",
    "for band_dir in band_dirs:\n",
    "    files = [f for f in os.listdir(band_dir) if f.lower().endswith(('.tif', '.img'))]\n",
    "    files.sort()\n",
    "    band_files_list.append(files)\n",
    "\n",
    "label_files = [f for f in os.listdir(label_dir) if f.lower().endswith(('.tif', '.img'))]\n",
    "label_files.sort()\n",
    "\n",
    "# =========================================================\n",
    "# 3. Region-based split for validation\n",
    "# =========================================================\n",
    "def extract_region_id(filename):\n",
    "    patterns = [\n",
    "        r'(Region[A-Z]+)_glacier',\n",
    "        r'([A-Za-z]+)_glacier',\n",
    "        r'(region[A-Z]+)_',\n",
    "        r'([A-Za-z0-9]+)_glacier'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, filename, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return filename.split('_')[0]\n",
    "\n",
    "region_files = {}\n",
    "for label_file in label_files:\n",
    "    region_id = extract_region_id(label_file)\n",
    "    if region_id not in region_files:\n",
    "        region_files[region_id] = []\n",
    "    region_files[region_id].append(label_file)\n",
    "\n",
    "regions = list(region_files.keys())\n",
    "print(f\"Available regions: {regions}\")\n",
    "\n",
    "if len(regions) < 2:\n",
    "    random.shuffle(label_files)\n",
    "    split_idx = int(0.8 * len(label_files))\n",
    "    train_label_files = label_files[:split_idx]\n",
    "    val_label_files = label_files[split_idx:]\n",
    "    print(\"⚠️ Only one region found, using random split\")\n",
    "else:\n",
    "    val_region = regions[0]\n",
    "    train_regions = regions[1:]\n",
    "    train_label_files = []\n",
    "    for region in train_regions:\n",
    "        train_label_files.extend(region_files[region])\n",
    "    val_label_files = region_files[val_region]\n",
    "\n",
    "print(f\"Training samples: {len(train_label_files)}\")\n",
    "print(f\"Validation samples: {len(val_label_files)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 4. Data Augmentation\n",
    "# =========================================================\n",
    "class SatelliteTransform:\n",
    "    def __init__(self, augment=False):\n",
    "        self.augment = augment\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        if self.augment:\n",
    "            if random.random() > 0.5:\n",
    "                image = torch.flip(image, [2])\n",
    "                mask = torch.flip(mask, [1])\n",
    "            if random.random() > 0.5:\n",
    "                image = torch.flip(image, [1])\n",
    "                mask = torch.flip(mask, [0])\n",
    "            rot = random.choice([0, 1, 2, 3])\n",
    "            image = torch.rot90(image, rot, [1, 2])\n",
    "            mask = torch.rot90(mask, rot, [0, 1])\n",
    "        return image, mask\n",
    "\n",
    "# =========================================================\n",
    "# 5. Dataset\n",
    "# =========================================================\n",
    "def extract_common_id(filename):\n",
    "    patterns = [\n",
    "        r'(Region[A-Z]+_glacier\\d+)',\n",
    "        r'([A-Za-z]+_glacier\\d+)',\n",
    "        r'([A-Za-z0-9]+_glacier\\d+)',\n",
    "        r'(glacier\\d+_[A-Za-z0-9]+)',\n",
    "        r'([A-Za-z0-9]+_\\d+)'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, filename, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    filename = filename.replace('B2_', '').replace('B3_', '').replace('B4_', '').replace('B6_', '').replace('B10_', '')\n",
    "    filename = filename.replace('Y_output_resized_', '').replace('mask_', '').replace('label_', '')\n",
    "    return os.path.splitext(filename)[0]\n",
    "\n",
    "class GlacierDataset(Dataset):\n",
    "    def __init__(self, band_dirs, band_files_list, label_dir, label_files, transform=None):\n",
    "        self.band_dirs = band_dirs\n",
    "        self.band_files_list = band_files_list\n",
    "        self.label_dir = label_dir\n",
    "        self.label_files = label_files\n",
    "        self.transform = transform\n",
    "        self.file_mapping = self._create_file_mapping()\n",
    "\n",
    "    def _create_file_mapping(self):\n",
    "        mapping = {}\n",
    "        for label_file in self.label_files:\n",
    "            common_id = extract_common_id(label_file)\n",
    "            band_files = []\n",
    "            for band_files_in_dir in self.band_files_list:\n",
    "                found_file = None\n",
    "                for band_file in band_files_in_dir:\n",
    "                    band_common_id = extract_common_id(band_file)\n",
    "                    if band_common_id == common_id:\n",
    "                        found_file = band_file\n",
    "                        break\n",
    "                band_files.append(found_file)\n",
    "            mapping[label_file] = band_files\n",
    "        return mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label_file = self.label_files[idx]\n",
    "        label_path = os.path.join(self.label_dir, label_file)\n",
    "        with rasterio.open(label_path) as src:\n",
    "            label_data = src.read(1)\n",
    "        label_tensor = torch.from_numpy(label_data).float()\n",
    "        band_files = self.file_mapping[label_file]\n",
    "        band_stack = []\n",
    "        for band_idx, band_file in enumerate(band_files):\n",
    "            if band_file is None:\n",
    "                band_data = np.zeros_like(label_data)\n",
    "            else:\n",
    "                band_path = os.path.join(self.band_dirs[band_idx], band_file)\n",
    "                with rasterio.open(band_path) as src:\n",
    "                    band_data = src.read(1)\n",
    "            band_stack.append(band_data)\n",
    "        image_tensor = torch.from_numpy(np.stack(band_stack, axis=0)).float()\n",
    "        if self.transform:\n",
    "            image_tensor, label_tensor = self.transform(image_tensor, label_tensor)\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "# =========================================================\n",
    "# 6. Model (U-Net)\n",
    "# =========================================================\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=5, out_ch=1):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_ch, 32)\n",
    "        self.enc2 = DoubleConv(32, 64)\n",
    "        self.enc3 = DoubleConv(64, 128)\n",
    "        self.enc4 = DoubleConv(128, 256)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "        self.up4 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec4 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(128, 64)\n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(64, 32)\n",
    "        self.final = nn.Conv2d(32, out_ch, 1)\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        d4 = self.up4(b)\n",
    "        d4 = torch.cat([d4, e4], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        return self.final(d1)\n",
    "\n",
    "# =========================================================\n",
    "# 7. Training Setup\n",
    "# =========================================================\n",
    "train_transform = SatelliteTransform(augment=True)\n",
    "val_transform = SatelliteTransform(augment=False)\n",
    "\n",
    "train_dataset = GlacierDataset(band_dirs, band_files_list, label_dir, train_label_files, transform=train_transform)\n",
    "val_dataset = GlacierDataset(band_dirs, band_files_list, label_dir, val_label_files, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "def calculate_mcc(predictions, targets):\n",
    "    pred_binary = (torch.sigmoid(predictions) > 0.5).float()\n",
    "    targets = targets.unsqueeze(1) if targets.ndim == 3 else targets\n",
    "    pred_flat = pred_binary.view(-1).cpu().numpy()\n",
    "    target_flat = targets.view(-1).cpu().numpy()\n",
    "    if np.all(pred_flat == pred_flat[0]) or np.all(target_flat == target_flat[0]):\n",
    "        return 0.0\n",
    "    return matthews_corrcoef(target_flat, pred_flat)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_ch=5, out_ch=1).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=3, factor=0.5)\n",
    "\n",
    "# =========================================================\n",
    "# 8. Training Loop\n",
    "# =========================================================\n",
    "num_epochs = 20\n",
    "best_mcc = -1.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Train\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        if masks.ndim == 3:\n",
    "            masks = masks.unsqueeze(1)\n",
    "        if masks.shape[2:] != outputs.shape[2:]:\n",
    "            masks = F.interpolate(masks.float(), size=outputs.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        loss = criterion(outputs, masks.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_mccs = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Val\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            if masks.ndim == 3:\n",
    "                masks = masks.unsqueeze(1)\n",
    "            if masks.shape[2:] != outputs.shape[2:]:\n",
    "                masks = F.interpolate(masks.float(), size=outputs.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss = criterion(outputs, masks.float())\n",
    "            val_loss += loss.item()\n",
    "            val_mccs.append(calculate_mcc(outputs, masks))\n",
    "    val_loss /= len(val_loader)\n",
    "    avg_val_mcc = np.mean(val_mccs)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f}, Val Loss {val_loss:.4f}, Val MCC {avg_val_mcc:.4f}\")\n",
    "\n",
    "    if avg_val_mcc > best_mcc:\n",
    "        best_mcc = avg_val_mcc\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "        print(f\"✅ Best model updated (MCC={best_mcc:.4f})\")\n",
    "\n",
    "    scheduler.step(avg_val_mcc)\n",
    "\n",
    "print(f\"Final Best MCC: {best_mcc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "093f4de6-f0cd-4974-9d2f-88d450f3f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of train_data:\n",
      "['Train']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Contents of train_data:\")\n",
    "print(os.listdir(\"train_data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0241b50-5203-4761-bfc3-ba285706dcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in train_data: ['Train']\n",
      "✅ Dataset root set to: train_data\\Train\n",
      "Band dirs: ['train_data\\\\Train\\\\Band1', 'train_data\\\\Train\\\\Band2', 'train_data\\\\Train\\\\Band3', 'train_data\\\\Train\\\\Band4', 'train_data\\\\Train\\\\Band5']\n",
      "Label dir: train_data\\Train\\label\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"train_data\"\n",
    "\n",
    "# Find the first directory inside train_data that contains Band1\n",
    "possible_subdirs = os.listdir(base_dir)\n",
    "print(\"Found in train_data:\", possible_subdirs)\n",
    "\n",
    "# If train_data directly has Band1, keep it\n",
    "if \"Band1\" in possible_subdirs:\n",
    "    dataset_root = base_dir\n",
    "else:\n",
    "    # Otherwise, enter the first subdirectory\n",
    "    dataset_root = os.path.join(base_dir, possible_subdirs[0])\n",
    "\n",
    "print(\"✅ Dataset root set to:\", dataset_root)\n",
    "\n",
    "# Now define band and label dirs\n",
    "band_dirs = [os.path.join(dataset_root, f\"Band{i}\") for i in range(1, 6)]\n",
    "label_dir = os.path.join(dataset_root, \"label\")\n",
    "\n",
    "print(\"Band dirs:\", band_dirs)\n",
    "print(\"Label dir:\", label_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6ffa3b2-cdaa-4b31-baab-b31e9659a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ train_data already exists, skipping extraction\n",
      "Band dirs: ['train_data\\\\Train\\\\Band1', 'train_data\\\\Train\\\\Band2', 'train_data\\\\Train\\\\Band3', 'train_data\\\\Train\\\\Band4', 'train_data\\\\Train\\\\Band5']\n",
      "Label dir: train_data\\Train\\label\n",
      "Available regions: ['Y']\n",
      "⚠️ Only one region found, using random split\n",
      "Training samples: 20\n",
      "Validation samples: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:32<00:00, 15.21s/it]\n",
      "Epoch 1/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss -1.3134, Val Loss -2.5509, Val MCC 0.0000\n",
      "✅ Best model updated (MCC=0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:30<00:00, 15.01s/it]\n",
      "Epoch 2/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss -17.9297, Val Loss -17.0819, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:31<00:00, 15.19s/it]\n",
      "Epoch 3/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss -28.1828, Val Loss -38.4345, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:29<00:00, 14.91s/it]\n",
      "Epoch 4/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss -37.6717, Val Loss -56.0392, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:28<00:00, 14.81s/it]\n",
      "Epoch 5/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss -47.5799, Val Loss -69.1643, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:24<00:00, 14.48s/it]\n",
      "Epoch 6/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss -56.2905, Val Loss -73.2359, Val MCC 0.0024\n",
      "✅ Best model updated (MCC=0.0024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:24<00:00, 14.44s/it]\n",
      "Epoch 7/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss -62.5147, Val Loss -74.8486, Val MCC 0.0062\n",
      "✅ Best model updated (MCC=0.0062)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:25<00:00, 14.56s/it]\n",
      "Epoch 8/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss -68.7261, Val Loss -81.5348, Val MCC 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train: 100%|██████████████████████████████████████████████████████████████| 10/10 [02:28<00:00, 14.80s/it]\n",
      "Epoch 9/20 - Val: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss -75.3968, Val Loss -89.1200, Val MCC 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:38<00:00, 15.86s/it]\n",
      "Epoch 10/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss -83.4486, Val Loss -99.1578, Val MCC 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:35<00:00, 15.54s/it]\n",
      "Epoch 11/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss -90.9042, Val Loss -111.7120, Val MCC 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:26<00:00, 14.60s/it]\n",
      "Epoch 12/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:13<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss -96.4960, Val Loss -116.5011, Val MCC 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:36<00:00, 15.64s/it]\n",
      "Epoch 13/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss -100.0061, Val Loss -118.6824, Val MCC 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:35<00:00, 15.56s/it]\n",
      "Epoch 14/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss -103.5234, Val Loss -120.6295, Val MCC 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:36<00:00, 15.62s/it]\n",
      "Epoch 15/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss -106.9715, Val Loss -123.2523, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:32<00:00, 15.25s/it]\n",
      "Epoch 16/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss -109.5510, Val Loss -124.7446, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:35<00:00, 15.53s/it]\n",
      "Epoch 17/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss -111.2842, Val Loss -125.4877, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [02:47<00:00, 16.71s/it]\n",
      "Epoch 18/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:14<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss -112.9333, Val Loss -126.2410, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [03:08<00:00, 18.88s/it]\n",
      "Epoch 19/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss -114.7032, Val Loss -128.0560, Val MCC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Train: 100%|█████████████████████████████████████████████████████████████| 10/10 [03:08<00:00, 18.83s/it]\n",
      "Epoch 20/20 - Val: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:12<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss -116.0190, Val Loss -128.7533, Val MCC 0.0000\n",
      "Final Best MCC: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# =========================================================\n",
    "# 1. Extract train.zip\n",
    "# =========================================================\n",
    "base_dir = \"train_data\"\n",
    "zip_path = \"train.zip\"\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(base_dir)\n",
    "    print(f\"✅ Extracted {zip_path} to {base_dir}\")\n",
    "else:\n",
    "    print(f\"⚠️ {base_dir} already exists, skipping extraction\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. Correct dataset root (inside 'Train' folder)\n",
    "# =========================================================\n",
    "dataset_root = os.path.join(base_dir, \"Train\")\n",
    "\n",
    "band_dirs = [os.path.join(dataset_root, f\"Band{i}\") for i in range(1, 6)]\n",
    "label_dir = os.path.join(dataset_root, \"label\")\n",
    "\n",
    "print(\"Band dirs:\", band_dirs)\n",
    "print(\"Label dir:\", label_dir)\n",
    "\n",
    "# =========================================================\n",
    "# 3. Collect band and label files\n",
    "# =========================================================\n",
    "band_files_list = []\n",
    "for band_dir in band_dirs:\n",
    "    files = [f for f in os.listdir(band_dir) if f.lower().endswith(('.tif', '.img'))]\n",
    "    files.sort()\n",
    "    band_files_list.append(files)\n",
    "\n",
    "label_files = [f for f in os.listdir(label_dir) if f.lower().endswith(('.tif', '.img'))]\n",
    "label_files.sort()\n",
    "\n",
    "# =========================================================\n",
    "# 4. Region-based split for validation\n",
    "# =========================================================\n",
    "def extract_region_id(filename):\n",
    "    patterns = [\n",
    "        r'(Region[A-Z]+)_glacier',\n",
    "        r'([A-Za-z]+)_glacier',\n",
    "        r'(region[A-Z]+)_',\n",
    "        r'([A-Za-z0-9]+)_glacier'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, filename, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return filename.split('_')[0]\n",
    "\n",
    "region_files = {}\n",
    "for label_file in label_files:\n",
    "    region_id = extract_region_id(label_file)\n",
    "    if region_id not in region_files:\n",
    "        region_files[region_id] = []\n",
    "    region_files[region_id].append(label_file)\n",
    "\n",
    "regions = list(region_files.keys())\n",
    "print(f\"Available regions: {regions}\")\n",
    "\n",
    "if len(regions) < 2:\n",
    "    random.shuffle(label_files)\n",
    "    split_idx = int(0.8 * len(label_files))\n",
    "    train_label_files = label_files[:split_idx]\n",
    "    val_label_files = label_files[split_idx:]\n",
    "    print(\"⚠️ Only one region found, using random split\")\n",
    "else:\n",
    "    val_region = regions[0]\n",
    "    train_regions = regions[1:]\n",
    "    train_label_files = []\n",
    "    for region in train_regions:\n",
    "        train_label_files.extend(region_files[region])\n",
    "    val_label_files = region_files[val_region]\n",
    "\n",
    "print(f\"Training samples: {len(train_label_files)}\")\n",
    "print(f\"Validation samples: {len(val_label_files)}\")\n",
    "\n",
    "# =========================================================\n",
    "# 5. Data Augmentation\n",
    "# =========================================================\n",
    "class SatelliteTransform:\n",
    "    def __init__(self, augment=False):\n",
    "        self.augment = augment\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        if self.augment:\n",
    "            if random.random() > 0.5:\n",
    "                image = torch.flip(image, [2])\n",
    "                mask = torch.flip(mask, [1])\n",
    "            if random.random() > 0.5:\n",
    "                image = torch.flip(image, [1])\n",
    "                mask = torch.flip(mask, [0])\n",
    "            rot = random.choice([0, 1, 2, 3])\n",
    "            image = torch.rot90(image, rot, [1, 2])\n",
    "            mask = torch.rot90(mask, rot, [0, 1])\n",
    "        return image, mask\n",
    "\n",
    "# =========================================================\n",
    "# 6. Dataset\n",
    "# =========================================================\n",
    "def extract_common_id(filename):\n",
    "    patterns = [\n",
    "        r'(Region[A-Z]+_glacier\\d+)',\n",
    "        r'([A-Za-z]+_glacier\\d+)',\n",
    "        r'([A-Za-z0-9]+_glacier\\d+)',\n",
    "        r'(glacier\\d+_[A-Za-z0-9]+)',\n",
    "        r'([A-Za-z0-9]+_\\d+)'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, filename, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    filename = filename.replace('B2_', '').replace('B3_', '').replace('B4_', '').replace('B6_', '').replace('B10_', '')\n",
    "    filename = filename.replace('Y_output_resized_', '').replace('mask_', '').replace('label_', '')\n",
    "    return os.path.splitext(filename)[0]\n",
    "\n",
    "class GlacierDataset(Dataset):\n",
    "    def __init__(self, band_dirs, band_files_list, label_dir, label_files, transform=None):\n",
    "        self.band_dirs = band_dirs\n",
    "        self.band_files_list = band_files_list\n",
    "        self.label_dir = label_dir\n",
    "        self.label_files = label_files\n",
    "        self.transform = transform\n",
    "        self.file_mapping = self._create_file_mapping()\n",
    "\n",
    "    def _create_file_mapping(self):\n",
    "        mapping = {}\n",
    "        for label_file in self.label_files:\n",
    "            common_id = extract_common_id(label_file)\n",
    "            band_files = []\n",
    "            for band_files_in_dir in self.band_files_list:\n",
    "                found_file = None\n",
    "                for band_file in band_files_in_dir:\n",
    "                    band_common_id = extract_common_id(band_file)\n",
    "                    if band_common_id == common_id:\n",
    "                        found_file = band_file\n",
    "                        break\n",
    "                band_files.append(found_file)\n",
    "            mapping[label_file] = band_files\n",
    "        return mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label_file = self.label_files[idx]\n",
    "        label_path = os.path.join(self.label_dir, label_file)\n",
    "        with rasterio.open(label_path) as src:\n",
    "            label_data = src.read(1)\n",
    "        label_tensor = torch.from_numpy(label_data).float()\n",
    "        band_files = self.file_mapping[label_file]\n",
    "        band_stack = []\n",
    "        for band_idx, band_file in enumerate(band_files):\n",
    "            if band_file is None:\n",
    "                band_data = np.zeros_like(label_data)\n",
    "            else:\n",
    "                band_path = os.path.join(self.band_dirs[band_idx], band_file)\n",
    "                with rasterio.open(band_path) as src:\n",
    "                    band_data = src.read(1)\n",
    "            band_stack.append(band_data)\n",
    "        image_tensor = torch.from_numpy(np.stack(band_stack, axis=0)).float()\n",
    "        if self.transform:\n",
    "            image_tensor, label_tensor = self.transform(image_tensor, label_tensor)\n",
    "        return image_tensor, label_tensor\n",
    "\n",
    "# =========================================================\n",
    "# 7. Model (U-Net)\n",
    "# =========================================================\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=5, out_ch=1):\n",
    "        super().__init__()\n",
    "        self.enc1 = DoubleConv(in_ch, 32)\n",
    "        self.enc2 = DoubleConv(32, 64)\n",
    "        self.enc3 = DoubleConv(64, 128)\n",
    "        self.enc4 = DoubleConv(128, 256)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "        self.up4 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec4 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(256, 128)\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(128, 64)\n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(64, 32)\n",
    "        self.final = nn.Conv2d(32, out_ch, 1)\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        d4 = self.up4(b)\n",
    "        d4 = torch.cat([d4, e4], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        return self.final(d1)\n",
    "\n",
    "# =========================================================\n",
    "# 8. Training Setup\n",
    "# =========================================================\n",
    "train_transform = SatelliteTransform(augment=True)\n",
    "val_transform = SatelliteTransform(augment=False)\n",
    "\n",
    "train_dataset = GlacierDataset(band_dirs, band_files_list, label_dir, train_label_files, transform=train_transform)\n",
    "val_dataset = GlacierDataset(band_dirs, band_files_list, label_dir, val_label_files, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "def calculate_mcc(predictions, targets):\n",
    "    pred_binary = (torch.sigmoid(predictions) > 0.5).float()\n",
    "    targets = targets.unsqueeze(1) if targets.ndim == 3 else targets\n",
    "    pred_flat = pred_binary.view(-1).cpu().numpy()\n",
    "    target_flat = targets.view(-1).cpu().numpy()\n",
    "    if np.all(pred_flat == pred_flat[0]) or np.all(target_flat == target_flat[0]):\n",
    "        return 0.0\n",
    "    return matthews_corrcoef(target_flat, pred_flat)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_ch=5, out_ch=1).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=3, factor=0.5)\n",
    "\n",
    "# =========================================================\n",
    "# 9. Training Loop\n",
    "# =========================================================\n",
    "num_epochs = 20\n",
    "best_mcc = -1.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Train\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        if masks.ndim == 3:\n",
    "            masks = masks.unsqueeze(1)\n",
    "        if masks.shape[2:] != outputs.shape[2:]:\n",
    "            masks = F.interpolate(masks.float(), size=outputs.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        loss = criterion(outputs, masks.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_mccs = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Val\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            if masks.ndim == 3:\n",
    "                masks = masks.unsqueeze(1)\n",
    "            if masks.shape[2:] != outputs.shape[2:]:\n",
    "                masks = F.interpolate(masks.float(), size=outputs.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss = criterion(outputs, masks.float())\n",
    "            val_loss += loss.item()\n",
    "            val_mccs.append(calculate_mcc(outputs, masks))\n",
    "    val_loss /= len(val_loader)\n",
    "    avg_val_mcc = np.mean(val_mccs)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss {train_loss:.4f}, Val Loss {val_loss:.4f}, Val MCC {avg_val_mcc:.4f}\")\n",
    "\n",
    "    if avg_val_mcc > best_mcc:\n",
    "        best_mcc = avg_val_mcc\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "        print(f\"✅ Best model updated (MCC={best_mcc:.4f})\")\n",
    "\n",
    "    scheduler.step(avg_val_mcc)\n",
    "\n",
    "print(f\"Final Best MCC: {best_mcc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dee8e5-c59e-44ec-9b52-cf61cc764a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
